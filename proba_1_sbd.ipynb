{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMk0FdyOV060oWP2NtrmNlR",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/lukaszplust/Projects/blob/main/proba_1_sbd.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "TEST\n",
        "\n",
        "WYNIK:\n",
        "\n",
        "Record 1 as ints: [3, 3, 5, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "Record 2 as ints: [4, 4, 2, 6, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
        "Record 1 loaded: Set [5, 3, 2]\n",
        "Record 2 loaded: Set [6, 4, 2, 1]\n",
        "Record 1 < Record 2: True\n",
        "Record 2 < Record 1: False\n",
        "\n",
        "WYJAŚNIENIE:\n",
        "\n",
        "Record 1 < Record 2 zwraca True, ponieważ największy element w Record 2 (6) jest większy niż największy element w Record 1 (5).\n",
        "Record 2 < Record 1 zwraca False, ponieważ największy element w Record 1 (5) nie jest większy niż największy element w Record 2 (6)."
      ],
      "metadata": {
        "id": "weq_sAd5SasH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Tworzenie rekordów\n",
        "#record1 = Record([3, 5, 2])\n",
        "#record2 = Record([4, 2, 6, 1])\n",
        "\n",
        "# Konwersja rekordów do listy liczb całkowitych\n",
        "#record1_ints = record1.save_to_ints()\n",
        "#record2_ints = record2.save_to_ints()\n",
        "#print(\"Record 1 as ints:\", record1_ints)\n",
        "#print(\"Record 2 as ints:\", record2_ints)\n",
        "\n",
        "# Tworzenie rekordów z listy liczb całkowitych\n",
        "#record1_loaded = Record.load_from_ints(record1_ints)\n",
        "#record2_loaded = Record.load_from_ints(record2_ints)\n",
        "#print(\"Record 1 loaded:\", record1_loaded)\n",
        "#print(\"Record 2 loaded:\", record2_loaded)\n",
        "\n",
        "# Porównanie rekordów\n",
        "#print(\"Record 1 < Record 2:\", record1 < record2)\n",
        "#print(\"Record 2 < Record 1:\", record2 < record1)"
      ],
      "metadata": {
        "id": "oajKTtiNSecT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# BUFFER_SIZE - określa liczbę rekordów, które będą przechowywane w buforze w jednym momencie.\n",
        "# Buforowanie poprawia wydajność operacji wejścia-wyjścia, minimalizując liczbę operacji odczytu i zapisu na dysk poprzez grupowanie ich w większe bloki.\n",
        "BUFFER_SIZE = 32\n",
        "\n",
        "# TO NADANE PRZEZ POLECENIE\n",
        "\n",
        "# SET_BYTES_SIZE - określa rozmiar w bajtach pojedynczego rekordu bez dodatkowych znaków. Zakłada się, że rekord zawiera dane o stałej długości (4 liczy * 2cyfry +3 spacje)\n",
        "SET_BYTES_SIZE = 15\n",
        "\n",
        "# Ta stała określa rozmiar w bajtach pojedynczego rekordu, włączając dodatkowy znak (nowa linia lub znak końca rekordu).\n",
        "# Zazwyczaj jest to znak '\\n' (nowa linia), który oddziela rekordy w pliku tekstowym\n",
        "RECORD_BYTES_SIZE = SET_BYTES_SIZE + 1\n",
        "\n",
        "# Ta stała określa całkowity rozmiar bufora w bajtach.\n",
        "# Jest to iloczyn liczby rekordów w buforze (BUFFER_SIZE) i rozmiaru jednego rekordu w bajtach (RECORD_BYTES_SIZE).\n",
        "# Bufor o takim rozmiarze będzie używany do operacji odczytu i zapisu blokowego, co zwiększa efektywność przez minimalizację liczby operacji I/O\n",
        "BYTES_BUFFER_SIZE = BUFFER_SIZE * RECORD_BYTES_SIZE\n"
      ],
      "metadata": {
        "id": "DYNf-43PklCB"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Należy zaimplementować symulację odczytu oraz zapisu blokowego jako oddzielną\n",
        "warstwę logiki programu. Warstwa ta powinna udostępniać warstwie sorowania co najmniej 2\n",
        "operacje: odczytu oraz zapisu pojedynczego rekordu.\n",
        "\n",
        "Runs - serie"
      ],
      "metadata": {
        "id": "7R1mIu7pkRdL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "WsL2fbvnjijt"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "class ReadBuffer:\n",
        "\n",
        "  def __init__(self, file_path):\n",
        "    #pdb.set_trace()\n",
        "    # pozycja odczytu w buforze\n",
        "    self.read_pos = 0\n",
        "    # rozmiar bufora, ustawiony na BUFFER_SIZE (liczba rekordow)\n",
        "    self.size = BUFFER_SIZE\n",
        "    # liczba rekordów obecnie załadowanych do bufora\n",
        "    self.loaded_size = 0\n",
        "    # lista przechowująca rekordy załadowane do bufora\n",
        "    self.buffer = []\n",
        "    # ścieżka do pliku, z którego będą odczytywane rekordy\n",
        "    self.file_path = file_path\n",
        "    # pozycja odczytu w pliku\n",
        "    self.file_pos = 0\n",
        "    # całkowity rozmiar pliku (w bajtach)\n",
        "    self.file_size = os.path.getsize(file_path)\n",
        "    # licznik operacji odczytu z dysku\n",
        "    self.disk_reads_count = 0\n",
        "    # inicjalnie ładuje pierwszą porcję danych do bufora\n",
        "    self.load_next()\n",
        "\n",
        "\n",
        "  # Muszę sprawdzić, czy są jeszcze dane do odczytu w pliku lub w buforze.\n",
        "  def has_more(self):\n",
        "        return (self.file_pos < self.file_size or self.read_pos < self.loaded_size)\n",
        "\n",
        "  # ŁADOWANIE KOLEJNEJ PORCJI DANYCH: Metoda load_next ładuje nową porcję danych z pliku do bufora.\n",
        "  def load_next(self):\n",
        "        #pdb.set_trace()\n",
        "        self.buffer = []\n",
        "        # buffering=0 disables buffering, it is desired, because buffering is implemented here, in code\n",
        "\n",
        "        # otwieram plik w trybie binarnym bez buforowania (buffering=0)\n",
        "        file = open(self.file_path, \"rb\", buffering=0)\n",
        "\n",
        "        # seek() function is used to change the position of the File Handle to a given specific position\n",
        "        # przesuwam wskaźnik odczytu pliku do self.file_pos\n",
        "        file.seek(self.file_pos)\n",
        "\n",
        "        # odczytuje maksymalnie BYTES_BUFFER_SIZE bajtów lub pozostałe bajty do końca pliku (self.file_size - self.file_pos)\n",
        "        bytes_to_read = min(BYTES_BUFFER_SIZE,self.file_size - self.file_pos)\n",
        "\n",
        "        temp_buffer = file.read(bytes_to_read)\n",
        "\n",
        "        # Odczytanie liczby bajtów, która nie jest wielokrotnością tej wielkości, oznaczałoby, że rekordy są niekompletne lub uszkodzone\n",
        "        # sprawdzam, czy liczba odczytanych bajtów jest wielokrotnością rozmiaru rekordu (RECORD_BYTES_SIZE)\n",
        "        if len(temp_buffer) % RECORD_BYTES_SIZE != 0:\n",
        "            raise Exception(\"Read bytes are not multiply of record size\")\n",
        "\n",
        "        # aktualizuje pozycję odczytu pliku (self.file_pos)\n",
        "        self.file_pos += bytes_to_read\n",
        "\n",
        "        # obliczam liczbę rekordów załadowanych do bufora (self.loaded_size)\n",
        "        self.loaded_size = bytes_to_read / RECORD_BYTES_SIZE\n",
        "\n",
        "        # Konwertuje odczytane bajty na listę rekordów\n",
        "        temp_ints = list(temp_buffer)\n",
        "\n",
        "        # dodaje liste rekordów do bufora (self.buffer)\n",
        "        for i in range(len(temp_buffer) // RECORD_BYTES_SIZE):\n",
        "            record_ints = temp_ints[\n",
        "                          RECORD_BYTES_SIZE * i:RECORD_BYTES_SIZE * (i + 1)\n",
        "                          ]\n",
        "            self.buffer.append(Record.load_from_ints(record_ints))\n",
        "\n",
        "        # zamykam plik i zwiększam licznik operacji odczytu z dysku (self.disk_reads_count)\n",
        "        file.close()\n",
        "        self.disk_reads_count += 1\n",
        "\n",
        "\n",
        "  # ODCZYT REKORDÓW: Metoda read_next zwraca następny rekord\n",
        "  def read_next(self):\n",
        "    #pdb.set_trace()\n",
        "    # sprawdzam, czy są jeszcze rekordy do odczytu\n",
        "    if not self.has_more():\n",
        "        return None\n",
        "\n",
        "    # jeśli są jakieś rekordy do odczytu to zwracam następny rekord z bufora\n",
        "    res_record = self.buffer[self.read_pos]\n",
        "    self.read_pos += 1\n",
        "\n",
        "    # jeśli pozycja odczytu osiągnie rozmiar bufora\n",
        "    if self.read_pos == self.size:\n",
        "\n",
        "        # ładuje kolejną porcję danych do bufora (self.load_next())\n",
        "        self.load_next()\n",
        "\n",
        "        # resetuje self.read_pos\n",
        "        self.read_pos = 0\n",
        "\n",
        "\n",
        "    return res_record\n",
        "\n",
        "  # PODGLĄD NASTĘPNEGO REKORDU: Metoda peek pozwala na podgląd następnego rekordu bez przesuwania wskaźnika odczytu\n",
        "  # Zwracam następny rekord bez zmiany pozycji odczytu. Jeśli bufor jest pusty, zwracam None.\n",
        "  def peek(self):\n",
        "\n",
        "    # pozycja odczytu w pliku = liczba rekordów obecnie załadowanych do bufora\n",
        "    if self.read_pos == self.loaded_size:\n",
        "        return None\n",
        "    result = self.buffer[self.read_pos]\n",
        "    return result\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# ITERACJA: Klasa jest iterowalna dzięki metodom __iter__ i __next__\n",
        "# Metody __iter__ i __next__ są częścią protokołu iteracji w Pythonie. Dzięki tym metodom można sprawić, że obiekt będzie iterowalny,\n",
        "# co oznacza, że można go używać w konstrukcjach takich jak pętle for, list comprehensions,\n",
        "# funkcje map, filter oraz inne operacje, które wymagają iterowalnych obiektów\n",
        "\n",
        "# INICJALIZACJA BUFORA: Konstruktor __init__ otwiera plik i ładuje pierwszą porcję danych do bufora\n",
        "# __iter__: Zwraca iterator (sam obiekt ReadBuffer)\n",
        "  def __iter__(self):\n",
        "    return self\n",
        "\n",
        "  # __next__: Zwraca następny rekord z bufora. Jeśli nie ma więcej rekordów, podnosi wyjątek StopIteration\n",
        "  def __next__(self):\n",
        "    next_record = self.read_next()\n",
        "    if next_record is None:\n",
        "      raise StopIteration\n",
        "    return next_record"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Klasa WriteBuffer implementuje mechanizm buforowania zapisu danych do pliku,\n",
        "# co może znacząco poprawić wydajność poprzez grupowanie operacji zapisu i minimalizację operacji na dysku.\n",
        "\n",
        "#Jej działanie jest zoptymalizowane pod kątem pracy z dużą ilością danych, pozwalając na kontrolowanie i\n",
        "# monitorowanie liczby zapisów na dysk oraz zachowanie kolejności zapisów (runów).\n",
        "\n",
        "class WriteBuffer:\n",
        "\n",
        "    # file_path: Ścieżka do pliku, do którego będą zapisywane dane\n",
        "    # append_mode: Parametr opcjonalny, domyślnie ustawiony na False.\n",
        "\n",
        "\n",
        "    # Jeśli ustawiony na True i plik istnieje, nowe dane będą dodawane na końcu istniejącego pliku\n",
        "\n",
        "    def __init__(self, file_path, append_mode=False):\n",
        "\n",
        "        # write_pos: Aktualna pozycja zapisu w buforze\n",
        "        self.write_pos = 0\n",
        "\n",
        "        # size: Rozmiar bufora, ustalony wcześniej jako BUFFER_SIZE\n",
        "        self.size = BUFFER_SIZE\n",
        "\n",
        "        # buffer: Lista, która będzie przechowywać zapisywane rekordy.\n",
        "        # początkowo wypełniona wartościami None\n",
        "        self.buffer = [None] * BUFFER_SIZE\n",
        "\n",
        "        # file_path: Ścieżka do pliku, do którego będą zapisywane dane\n",
        "        self.file_path = file_path\n",
        "\n",
        "        # usuwam istniejący plik, jeśli append_mode jest ustawione na False i plik już istnieje\n",
        "        if not append_mode and os.path.isfile(file_path):\n",
        "            os.remove(file_path)\n",
        "\n",
        "        # runs_written: Liczba wykonanych serii do pliku\n",
        "        self.runs_written = 0\n",
        "\n",
        "        # last_written: Ostatni zapisany rekord\n",
        "        self.last_written = None\n",
        "\n",
        "        # disk_writes_count: Licznik operacji zapisu na dysku\n",
        "        self.disk_writes_count = 0\n",
        "\n",
        "\n",
        "    # write_next(self, record): Metoda służąca do zapisu kolejnego rekordu do bufora\n",
        "    # record: Rekord do zapisania\n",
        "    def write_next(self, record):\n",
        "\n",
        "        # Sprawdzenie, czy aktualnie zapisywany rekord (record) jest mniejszy od ostatnio zapisanego (self.last_written).\n",
        "        # Jeśli tak, zwiększa licznik runs_written\n",
        "        if record < self.last_written:\n",
        "            self.runs_written += 1\n",
        "\n",
        "        # Sprawdzenie, czy bufor (self.buffer) jest pełny (self.write_pos == self.size).\n",
        "        # Jeśli tak, wywołuje metodę flush(), która zapisuje zawartość bufora do pliku.\n",
        "        if self.write_pos == self.size:\n",
        "            self.flush()\n",
        "\n",
        "        # zapisuje rekord do bufora na aktualnej pozycji self.write_pos\n",
        "        self.buffer[self.write_pos] = record\n",
        "        self.write_pos += 1\n",
        "\n",
        "        # ustawiam self.last_written na aktualnie zapisany rekord (record)\n",
        "        self.last_written = record\n",
        "\n",
        "\n",
        "    # save_next(self): Metoda zapisująca zawartość bufora do pliku\n",
        "    def save_next(self):\n",
        "\n",
        "        # tworzę listę ints_to_write, która zawiera zserializowane wartości rekordów znajdujących się w buforze.\n",
        "        ints_to_write = []\n",
        "\n",
        "\n",
        "        for record in self.buffer[0:self.write_pos]:\n",
        "            ints_to_write += record.save_to_ints()  # type: ignore\n",
        "\n",
        "        # otwieram plik w trybie do dopisywania binarnego (\"ab\"), bez buforowania (buffering=0)\n",
        "        file = open(self.file_path, \"ab\", buffering=0)\n",
        "\n",
        "        # konwertuje listę ints_to_write na tablicę bajtów (bytearray) i zapisuje ją do pliku\n",
        "        file.write(bytearray(ints_to_write))\n",
        "\n",
        "        file.close()\n",
        "\n",
        "        # zwiększam licznik operacji zapisu na dysku (self.disk_writes_count)\n",
        "        self.disk_writes_count += 1\n",
        "\n",
        "    # flush(self): Metoda zapisująca zawartość aktualnie wypełnionego bufora do pliku\n",
        "    def flush(self):\n",
        "\n",
        "        # sprawdzam, czy self.write_pos (aktualna pozycja zapisu w buforze) jest większa od 0.\n",
        "        # Jeśli tak, wywołuje metodę save_next() do zapisania danych\n",
        "        if self.write_pos > 0:\n",
        "            self.save_next()\n",
        "\n",
        "            # resetuje self.write_pos do 0, przygotowując bufor do dalszych operacji zapisu\n",
        "            self.write_pos = 0"
      ],
      "metadata": {
        "id": "Z9kjDZw4XhR5"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdb\n",
        "class Record:\n",
        "\n",
        "\n",
        "    # konstruktor inicjalizuje obiekt Record z listą elementów (items)\n",
        "    def __init__(self, items):\n",
        "        self.items = items\n",
        "\n",
        "    # Metoda ta służy do tworzenia obiektu Record z listy liczb całkowitych.\n",
        "\n",
        "\n",
        "    @staticmethod\n",
        "    def load_from_ints(record_ints):\n",
        "        #pdb.set_trace()\n",
        "        # #Pierwsza liczba (set_length) określa długość zestawu\n",
        "        set_length = record_ints[0]\n",
        "        # kolejne liczby to elementy tego zestawu\n",
        "        set_items = record_ints[1:set_length + 1]\n",
        "\n",
        "        # tworzę nowy obiekt Record z tymi elementami\n",
        "        return Record(set_items)\n",
        "\n",
        "\n",
        "\n",
        "    def save_to_ints(self):\n",
        "\n",
        "        # wynikowa lista zawiera długość zestawu jako pierwszy element, następnie elementy zestawu\n",
        "        result = [len(self.items), *self.items]\n",
        "\n",
        "        # resztę wypełniają zera, aby osiągnąć rozmiar RECORD_BYTES_SIZE\n",
        "        zeropad = [0] * (RECORD_BYTES_SIZE - len(result))\n",
        "        result += zeropad\n",
        "        return result\n",
        "\n",
        "    # metoda __repr__(self) - zwraca czytelną reprezentację obiektu Record jako posortowaną listę elementów w odwrotnej kolejności (reverse=True) .\n",
        "    def __repr__(self):\n",
        "        return f\"Set {sorted(self.items, reverse=True)}\"\n",
        "\n",
        "\n",
        "\n",
        "    # Metoda __lt__ w klasie Record implementuje operator porównania \"mniejszy niż\" (<) dla obiektów tej klasy.\n",
        "    # Dzięki tej metodzie można porównywać dwa obiekty Record i określić, czy jeden jest mniejszy od drugiego zgodnie z określonymi kryteriami.\n",
        "    def __lt__(self, other):\n",
        "        # Jeśli drugi obiekt (other) jest None, obecny obiekt (self) jest uznawany za mniejszy\n",
        "        if other is None:\n",
        "            return True\n",
        "        #pdb.set_trace()\n",
        "        self_items_copy = self.items[:]\n",
        "        other_items_copy = other.items[:]\n",
        "\n",
        "        # Jeśli element z tej listy znajduje się również w kopii listy elementów drugiego obiektu (other_items_copy), to ten element jest usuwany z obu list\n",
        "        for item in self_items_copy:\n",
        "            if item in other_items_copy:\n",
        "                self_items_copy.remove(item)\n",
        "                other_items_copy.remove(item)\n",
        "\n",
        "\n",
        "        # Jeśli po usunięciu wspólnych elementów lista elementów drugiego obiektu (other_items_copy) jest pusta, oznacza to,\n",
        "        # że wszystkie jego elementy były wspólne z obecnym obiektem, więc obecny obiekt (self) nie jest mniejszy od drugiego obiektu (False).\n",
        "        if len(other_items_copy) == 0:\n",
        "            return False\n",
        "\n",
        "        # Jeśli lista elementów obecnego obiektu (self_items_copy) jest pusta, oznacza to,\n",
        "        # że wszystkie jego elementy były wspólne z drugim obiektem, więc obecny obiekt (self) jest mniejszy od drugiego obiektu (True)\n",
        "        elif len(self_items_copy) == 0:\n",
        "            return True\n",
        "\n",
        "        # Jeśli obie listy zawierają jeszcze jakieś elementy, metoda porównuje największe pozostałe elementy z obu list\n",
        "        # (s_max dla obecnego obiektu i o_max dla drugiego obiektu).\n",
        "        s_max = max(self_items_copy)\n",
        "        o_max = max(other_items_copy)\n",
        "\n",
        "        # # Obecny obiekt jest mniejszy, jeśli największy element z drugiego obiektu (o_max) jest większy od największego elementu z obecnego obiektu (s_max)\n",
        "        return o_max > s_max"
      ],
      "metadata": {
        "id": "UNGvmkezwVzd"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Klasa RunIterator działa jako iterator umożliwiający iterację po kolejnych rekordach z obiektu ReadBuffer.\n",
        "\n",
        "#Jest zoptymalizowana pod kątem pracy z dużymi zbiorami danych, zapewniając efektywne odczytywanie i monitorowanie przebiegów rekordów.\n",
        "\n",
        "# Flagę end_of_run wykorzystuje się do wykrywania końca bieżącego przebiegu rekordów,\n",
        "# co jest istotne w algorytmach sortowania, takich jak naturalne scalanie.\n",
        "\n",
        "# Dzięki implementacji interfejsu iteratora (__iter__ i __next__), klasa RunIterator może być używana w konstrukcjach iteracyjnych Pythona,\n",
        "#co znacząco ułatwia przetwarzanie i analizę danych\n",
        "\n",
        "class RunIterator:\n",
        "\n",
        "    # Konstruktor inicjuje nową instancję RunIterator\n",
        "    def __init__(self, read_buffer):\n",
        "\n",
        "        # read_buffer: Obiekt ReadBuffer, który zawiera dane do iteracj\n",
        "        self.read_buffer = read_buffer\n",
        "\n",
        "        # current_record: Aktualny rekord, który jest aktualnie przetwarzany\n",
        "        self.current_record = None\n",
        "\n",
        "        # end_of_run: Flaga określająca, czy aktualny przebieg (run) rekordów dobiegł końca\n",
        "        self.end_of_run = False\n",
        "\n",
        "\n",
        "    # read_next(self): Metoda służy do odczytywania kolejnych rekordów z read_buffer\n",
        "    def read_next(self):\n",
        "\n",
        "        # sprawdzam, czy flaga end_of_run jest ustawiona na True.\n",
        "        # Jeśli tak, zwraca None, co oznacza, że nie ma więcej rekordów do odczytu\n",
        "        if self.end_of_run:\n",
        "            return None\n",
        "\n",
        "        # Odczytuje następny rekord z read_buffer i przypisuje go do self.current_record\n",
        "        self.current_record = self.read_buffer.read_next()\n",
        "\n",
        "        # Jeśli self.current_record jest None, również zwraca None, co sygnalizuje koniec danych do odczytu\n",
        "        if self.current_record is None:\n",
        "            return None\n",
        "\n",
        "        # Korzystając z metody peek() z read_buffer, sprawdzam następny rekord bez przesuwania wskaźnika odczytu.\n",
        "        next_record = self.read_buffer.peek()\n",
        "\n",
        "        # Jeśli istnieje i jest mniejszy niż self.current_record, ustawia end_of_run na True,\n",
        "        # co oznacza zakończenie bieżącego przebiegu rekordów\n",
        "        if next_record is not None and next_record < self.current_record:\n",
        "            self.end_of_run = True\n",
        "\n",
        "        return self.current_record\n",
        "\n",
        "\n",
        "    def __iter__(self):\n",
        "        return self\n",
        "\n",
        "    # __next__(self): Metoda zwracająca następny rekord w iteracji\n",
        "    def __next__(self):\n",
        "\n",
        "        # Wywołuje metodę read_next() do odczytania kolejnego rekordu\n",
        "        res_record = self.read_next()\n",
        "\n",
        "        # Jeśli res_record (rezultat odczytania) jest None, podnosi wyjątek StopIteration, co sygnalizuje zakończenie iteracji\n",
        "        if res_record is None:\n",
        "            raise StopIteration\n",
        "        return res_record"
      ],
      "metadata": {
        "id": "8zPBGW5FacqC"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja print_tape(file_name) umożliwia analizę zawartości taśmy (pliku) poprzez\n",
        "# wypisanie każdego rekordu oraz podsumowanie liczby serii i rekordów.\n",
        "\n",
        "# Jest to przydatne narzędzie do weryfikacji poprawności danych, przetwarzania wstępnego przed dalszymi operacjami,\n",
        "# takimi jak sortowanie, analiza lub transformacja danych.\n",
        "\n",
        "# Dzięki iteracyjnemu podejściu za pomocą RunIterator funkcja może obsługiwać nawet duże zbiory danych efektywnie,\n",
        "# minimalizując zużycie pamięci i zapewniając możliwość stopniowego przetwarzania danych\n",
        "\n",
        "\n",
        "def print_tape(file_name):\n",
        "\n",
        "    # wyświetlam nagłówek, który informuje o nazwie taśmy (pliku), którą będe przetwarzać.\n",
        "    print(f\"[ .. ] Tape {file_name}\\n\")\n",
        "\n",
        "    # tworzy instancję ReadBuffer dla podanego pliku file_name, który zawiera dane\n",
        "    buffer = ReadBuffer(file_name)\n",
        "\n",
        "    # series_count - inicjacja liczby serii\n",
        "    series_count = 0\n",
        "\n",
        "    # records_count inicjacja liczby rekordów\n",
        "    records_count = 0\n",
        "\n",
        "\n",
        "    # while buffer.has_more(): sprawdza, czy w buforze są jeszcze dane do odczytu\n",
        "    while buffer.has_more():\n",
        "\n",
        "        # ri = RunIterator(buffer) tworzy iterator RunIterator na podstawie buffer,\n",
        "        # co umożliwia iteracyjne odczytywanie kolejnych rekordów z taśmy\n",
        "        ri = RunIterator(buffer)\n",
        "\n",
        "        # for record in ri: iteruje po rekordach zwróconych przez RunIterator\n",
        "        for record in ri:\n",
        "\n",
        "            # każdy rekord jest wyświetlany za pomocą print(record)\n",
        "            print(record)\n",
        "\n",
        "            # licznik records_count zwiększa się o jeden po każdym wyświetleniu rekordu\n",
        "            records_count += 1\n",
        "\n",
        "        series_count += 1\n",
        "\n",
        "        # po przejściu przez wszystkie rekordy w bieżącej serii,\n",
        "        # wyświetlam print(\"~ series end ~\") oznaczające koniec serii rekordów\n",
        "        print(\"~ series end ~\")\n",
        "\n",
        "    # po zakończeniu iteracji po wszystkich serii, wyświetlam podsumowanie\n",
        "\n",
        "    # Series count: liczba serii (grup rekordów) na taśmie\n",
        "    print(f\"\\n[ ^- ] Series count: {series_count}\")\n",
        "\n",
        "    # Records count: całkowita liczba rekordów na taśmie\n",
        "    print(f\"[ ^- ] Records count: {records_count}\")"
      ],
      "metadata": {
        "id": "1w7Oa-t0dSY_"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja print_runs(file_name, n) jest użyteczna do weryfikacji zawartości i\n",
        "# struktury danych na taśmie (pliku tekstowym) poprzez wypisanie pierwszych n serii.\n",
        "\n",
        "# Umożliwia to szybkie zrozumienie, jak dane są zorganizowane i czy są zgodne z oczekiwaniami.\n",
        "# Dzięki użyciu ReadBuffer i RunIterator, funkcja może efektywnie zarządzać dużymi plikami danych,\n",
        "# minimalizując obciążenie pamięciowe poprzez iteracyjne przetwarzanie\n",
        "\n",
        "\n",
        "def print_runs(file_name, n):\n",
        "\n",
        "    # wyświetlam informację o tym, że zostaną wydrukowane pierwsze n serii danych z pliku file_name\n",
        "    print(f\"Printing first {n} runs from {file_name}\")\n",
        "\n",
        "    # buff = ReadBuffer(file_name): Tworzy instancję ReadBuffer dla podanego pliku file_name,\n",
        "    # co umożliwia odczyt danych z taśm\n",
        "    buff = ReadBuffer(file_name)\n",
        "\n",
        "    # for i in range(n): Pętla iteruje n razy, co odpowiada ilości serii (run), które chcemy wydrukować.\n",
        "    for i in range(n):\n",
        "\n",
        "        # print(f\"\\nRun {i}:\"): wyświetlam nagłówek informujący o numerze aktualnej serii.\n",
        "        print(f\"\\nRun {i}:\")\n",
        "\n",
        "        # ri = RunIterator(buff): Tworzy iterator RunIterator na podstawie bufora buff.\n",
        "        # RunIterator pozwala na odczyt kolejnych rekordów z taśmy\n",
        "        ri = RunIterator(buff)\n",
        "\n",
        "        # for record in ri: Pętla iteruje po rekordach zwróconych przez RunIterator\n",
        "        for record in ri:\n",
        "            # Każdy rekord jest wyświetlany za pomocą print(record),\n",
        "            # co umożliwia wizualizację zawartości kolejnych serii danych\n",
        "            print(record)"
      ],
      "metadata": {
        "id": "79tcQdAsU4i7"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja runs_count(file_name) jest użyteczna do określenia liczby serii (run)\n",
        "# danych znajdujących się w pliku tekstowym.\n",
        "\n",
        "# Jest to przydatne w kontekście analizy i zarządzania dużymi zbiorami danych,\n",
        "# gdzie istotne jest zrozumienie ich struktury i organizacji.\n",
        "\n",
        "# Dzięki wykorzystaniu ReadBuffer i RunIterator, funkcja efektywnie zarządza odczytem danych z pliku,\n",
        "# co jest szczególnie przydatne przy pracy z dużymi plikami, gdzie nie można założyć,\n",
        "#że cały plik będzie przechowywany w pamięci operacyjnej na raz\n",
        "\n",
        "def runs_count(file_name):\n",
        "\n",
        "    # Zmienna rc inicjalizowana jest na początku jako zero.\n",
        "    # Będzie ona przechowywać liczbę serii (run) danych.\n",
        "    rc = 0\n",
        "\n",
        "    # buff = ReadBuffer(file_name): Tworze instancję ReadBuffer dla podanego pliku file_name,\n",
        "    # co umożliwia odczyt danych z taśmy\n",
        "    buff = ReadBuffer(file_name)\n",
        "\n",
        "    # while buff.has_more():: Pętla wykonuje się dopóki są dostępne kolejne rekordy do odczytu z bufora buff\n",
        "    while buff.has_more():\n",
        "\n",
        "        # ri = RunIterator(buff): Tworzy iterator RunIterator na podstawie bufora buff.\n",
        "        # RunIterator pozwala na odczyt kolejnych rekordów z taśmy.\n",
        "        ri = RunIterator(buff)\n",
        "\n",
        "        # for _ in ri: Pętla iteruje po rekordach zwróconych przez RunIterator,\n",
        "        # ale nie wykonuje żadnych operacji wewnętrznych (pass oznacza pominięcie).\n",
        "        for _ in ri:\n",
        "            pass\n",
        "\n",
        "        # Po przeiterowaniu wszystkich rekordów w aktualnej serii,\n",
        "        # inkrementuje się zmienną rc o jeden, co zwiększa liczbę serii.\n",
        "        rc += 1\n",
        "\n",
        "    # Po zakończeniu iteracji po wszystkich serii,\n",
        "    # funkcja zwraca całkowitą liczbę serii (run), które zostały policzone\n",
        "    return rc"
      ],
      "metadata": {
        "id": "vLOjOJAQiNss"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja prepare_tapes() ma na celu przygotowanie początkowego stanu taśm t1, t2 i t3\n",
        "# przed wykonaniem operacji sortowania lub innego przetwarzania danych na tych taśmach.\n",
        "\n",
        "# Dzięki temu:\n",
        "\n",
        "#Taśma t1 jest zapełniana danymi z taśmy startowej start_tape\n",
        "\n",
        "# Taśmy t2 i t3 są czyszczone, aby usunąć ewentualne wcześniejsze dane,\n",
        "# co zapobiega konfliktom lub problemom podczas dalszych operacji.\n",
        "\n",
        "# To wszystko sprawia, że funkcja jest ważnym elementem w procesie przygotowywania\n",
        "# danych do dalszej obróbki, zapewniając, że wszystkie taśmy są gotowe i czyste\n",
        "# przed rozpoczęciem głównego algorytmu sortowania lub przetwarzania danych.\n",
        "\n",
        "\n",
        "def prepare_tapes():\n",
        "\n",
        "    # tworze obiekt WriteBuffer o nazwie t1_dest, który będzie służył do zapisu danych do taśmy t1\n",
        "    t1_dest = WriteBuffer(\"/content/t1\")\n",
        "\n",
        "    # otwieram bufor do odczytu danych z pliku start_tape za pomocą ReadBuffer\n",
        "\n",
        "    # Operacja ta kontynuuje się, dopóki istnieją kolejne rekordy do odczytu z taśmy startowej\n",
        "    for record in ReadBuffer(\"/content/start_tape\"):\n",
        "\n",
        "        # Każdy rekord odczytany z ReadBuffer jest następnie zapisywany\n",
        "        # do WriteBuffer (t1_dest) za pomocą metody write_next(record)\n",
        "        t1_dest.write_next(record)\n",
        "\n",
        "    # Po zapisaniu wszystkich rekordów do WriteBuffer (t1_dest),\n",
        "    # wywoływołuje metodę flush(), która zapisuje zawartość bufora do pliku t1\n",
        "    t1_dest.flush()\n",
        "\n",
        "    # Sprawdzam, czy istnieją pliki t2 i t3\n",
        "\n",
        "    # Operacja ta zapewnia, że przed dalszymi operacjami na taśmach t2 i t3,\n",
        "    # ich zawartość jest wyczyszczona lub zresetowana\n",
        "    if os.path.isfile(\"/content/t2.txt\"):\n",
        "        os.remove(\"/content/t2.txt\")\n",
        "    if os.path.isfile(\"/content/t3.txt\"):\n",
        "        os.remove(\"/content/t3.txt\")"
      ],
      "metadata": {
        "id": "qO07oPC7jCP0"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Klasa MetaInfo może być używana do gromadzenia i przechowywania informacji o operacjach wejścia/wyjścia\n",
        "# oraz liczbie przebiegów w trakcie działania algorytmu sortowania.\n",
        "\n",
        "# Dzięki temu można łatwo monitorować i optymalizować wydajność algorytmu\n",
        "\n",
        "class MetaInfo:\n",
        "    def __init__(self, reads_count, writes_count, runs_count):\n",
        "\n",
        "        # reads_count: Liczba operacji odczytu z dysku\n",
        "        self.reads_count = reads_count\n",
        "\n",
        "        # writes_count: Liczba operacji zapisu na dysk\n",
        "        self.writes_count = writes_count\n",
        "\n",
        "        # runs_count: Liczba przebiegów (runs) wykonanych podczas sortowania\n",
        "        self.runs_count = runs_count"
      ],
      "metadata": {
        "id": "KyRDmniampZy"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funckja distribute rozdziela rekordy z jednego źródłowego pliku na dwa docelowe pliki, tworząc w nich sekwencje posortowane\n",
        "\n",
        "# Dzięki przełączaniu buforów (t2_buffer i t3_buffer), funkcja może naprzemiennie\n",
        "# zapisywać rekordy do dwóch plików, co umożliwia podział rekordów na posortowane sekwencje (runs).\n",
        "\n",
        "# Flushing buforów na końcu zapisuje wszystkie pozostałe dane z buforów do plików, zapewniając,\n",
        "# że wszystkie dane są zapisywane i bufor jest pusty przed kolejnymi operacjami\n",
        "\n",
        "\n",
        "\n",
        "# source_tape_path - ścieżka do pliku źródłowego, z którego będą odczytywane rekordy.\n",
        "\n",
        "# first_dest_path - ścieżka do pierwszego pliku docelowego, do którego będą zapisywane rekordy.\n",
        "# second_dest_path - ścieżka do drugiego pliku docelowego, do którego będą zapisywane rekordy.\n",
        "\n",
        "def distribute(source_tape_path, first_dest_path, second_dest_path):\n",
        "\n",
        "    #inicjalizacja buforów\n",
        "    t1_buffer = ReadBuffer(source_tape_path)\n",
        "    t2_buffer = WriteBuffer(first_dest_path)\n",
        "    t3_buffer = WriteBuffer(second_dest_path)\n",
        "\n",
        "    # t1_buffer.read_next(): Odczytuje następny rekord z pliku źródłowego za pośrednictwem bufora odczytu (ReadBuffer)\n",
        "    # zmienna last_record przechowuje ten odczytany rekord, który stanie się punktem odniesienia dla kolejnych rekordów.\n",
        "    last_record = t1_buffer.read_next()\n",
        "\n",
        "\n",
        "    # t2_buffer.write_next(last_record): Zapisuje odczytany rekord (last_record) do bufora zapisu (WriteBuffer),\n",
        "    # który jest połączony z pierwszym plikiem docelowym (first_dest_path)\n",
        "    # To ustanawia początkową sekwencję rekordów (run) w pierwszym pliku docelowym\n",
        "    t2_buffer.write_next(last_record)\n",
        "\n",
        "    # dest_buffer reprezentuje aktualny bufor zapisu, do którego będą zapisywane kolejne rekordy\n",
        "    dest_buffer = t2_buffer\n",
        "\n",
        "    i = 0\n",
        "\n",
        "    # iteruje przez wszystkie rekordy odczytywane z bufora źródłowego t1_buffer\n",
        "    for record in t1_buffer:\n",
        "        #pdb.set_trace()\n",
        "        # Not sorted pair of records\n",
        "\n",
        "        # Jeśli bieżący rekord (record) jest mniejszy niż poprzedni rekord (last_record),\n",
        "        # oznacza to koniec bieżącej sekwencji posortowanej (run) i\n",
        "        # przełączenie bufora docelowego (dest_buffer) na drugi\n",
        "\n",
        "        # Jeśli bieżący rekord (record) jest mniejszy niż poprzedni rekord (last_record),\n",
        "        # oznacza to koniec bieżącej sekwencji posortowanej (run)\n",
        "\n",
        "        if record < last_record:\n",
        "            # Toggle\n",
        "            # Jeśli aktualnym buforem docelowym jest t2_buffer, przełącza na t3_buffer i odwrotnie\n",
        "            if dest_buffer == t2_buffer:\n",
        "                dest_buffer = t3_buffer\n",
        "            else:\n",
        "                dest_buffer = t2_buffer\n",
        "            i += 1\n",
        "\n",
        "        # Jeśli aktualnym buforem docelowym jest t2_buffer, zapisuje bieżący rekord do t2_buffer\n",
        "        if dest_buffer == t2_buffer:\n",
        "            t2_buffer.write_next(record)\n",
        "        # Jeśli aktualnym buforem docelowym jest t3_buffer, zapisuje bieżący rekord do t3_buffer\n",
        "        else:\n",
        "            t3_buffer.write_next(record)\n",
        "\n",
        "        # Ustawia last_record na bieżący rekord, aby w następnej iteracji móc porównać z nowym rekordem\n",
        "        last_record = record\n",
        "\n",
        "    # t2_buffer.flush() - Zapisuje wszystkie pozostałe dane z bufora t2_buffer do odpowiedniego pliku\n",
        "    t2_buffer.flush()\n",
        "    # t3_buffer.flush() - Zapisuje wszystkie pozostałe dane z bufora t3_buffer do odpowiedniego pliku\n",
        "    t3_buffer.flush()\n",
        "\n",
        "    # t1_buffer.disk_reads_count: Liczba operacji odczytu z dysku\n",
        "    return MetaInfo(t1_buffer.disk_reads_count,\n",
        "                    # t2_buffer.disk_writes_count + t3_buffer.disk_writes_count: Łączna liczba operacji zapisu na dysku dla obu buforów\n",
        "                    t2_buffer.disk_writes_count + t3_buffer.disk_writes_count,\n",
        "                    # t2_buffer.runs_written + t3_buffer.runs_written: Łączna liczba sekwencji posortowanych (runs) zapisanych do obu buforów\n",
        "                    t2_buffer.runs_written + t3_buffer.runs_written)"
      ],
      "metadata": {
        "id": "tIt3D-CT7Bjx"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja merge_runs jest używana do scalenia dwóch posortowanych sekwencji rekordów w jedną posortowaną sekwencję.\n",
        "# Jest to podstawowa operacja w algorytmach sortowania zewnętrznego, takich jak sortowanie naturalne czy sortowanie przez scalanie\n",
        "\n",
        "# Używanie bufora WriteBuffer do zapisywania scalonych rekordów minimalizuje liczbę operacji zapisu na dysku, co zwiększa wydajność.\n",
        "\n",
        "# Funkcja wykorzystuje iteratory RunIterator do odczytu posortowanych sekwencji, co umożliwia efektywne porównywanie i scalanie rekordów\n",
        "\n",
        "# Funkcja merge_runs jest kluczowym elementem w implementacji algorytmów sortowania, które operują na dużych zestawach danych przechowywanych na dysku.\n",
        "# Jej zadaniem jest zapewnienie, że sekwencje rekordów są scalane w sposób wydajny i zgodny z wymogami sortowania\n",
        "\n",
        "\n",
        "# sekwencje te są odczytywane z dwóch iteratorów RunIterator (rit1 i rit2)\n",
        "# wynikowy posortowany ciąg jest zapisywany do bufora WriteBuffer\n",
        "def merge_runs(rit1, rit2, write_buffer: WriteBuffer):\n",
        "\n",
        "    # rit1_curr i rit2_curr przechowują bieżące rekordy odczytane z iteratorów rit1 i rit2\n",
        "    rit1_curr = rit1.read_next()\n",
        "    rit2_curr = rit2.read_next()\n",
        "\n",
        "    # Pętla działa dopóki oba iteratory mają dostępne rekordy\n",
        "    while rit1_curr is not None and rit2_curr is not None:\n",
        "\n",
        "        # Jeśli bieżący rekord z rit1 jest mniejszy niż bieżący rekord z rit2,\n",
        "        if rit1_curr < rit2_curr:\n",
        "            # rekord z rit1 jest zapisywany do bufora wyjściowego (write_buffer)\n",
        "            write_buffer.write_next(rit1_curr)\n",
        "            # pobierany jest następny rekord z rit1\n",
        "            rit1_curr = rit1.read_next()\n",
        "        else:\n",
        "            # W przeciwnym razie rekord z rit2 jest zapisywany do bufora wyjściowego\n",
        "            write_buffer.write_next(rit2_curr)\n",
        "            # następnie pobierany jest kolejny rekord z rit2\n",
        "            rit2_curr = rit2.read_next()\n",
        "\n",
        "    # Jeśli pozostały jakiekolwiek rekordy w rit1\n",
        "    if rit1_curr is not None:\n",
        "        # bieżący rekord jest zapisywany do bufora\n",
        "        write_buffer.write_next(rit1_curr)\n",
        "        # następnie wszystkie pozostałe rekordy z rit1 są zapisywane w pętli\n",
        "        for r in rit1:\n",
        "            write_buffer.write_next(r)\n",
        "    # Jeśli pozostały jakiekolwiek rekordy w rit2\n",
        "    if rit2_curr is not None:\n",
        "        # bieżący rekord jest zapisywany do bufora\n",
        "        write_buffer.write_next(rit2_curr)\n",
        "        # następnie wszystkie pozostałe rekordy z rit2 są zapisywane w pętli\n",
        "        for r in rit2:\n",
        "            write_buffer.write_next(r)"
      ],
      "metadata": {
        "id": "pGhQhC-3-z4N"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja merge jest kluczowym elementem algorytmu sortowania zewnętrznego.\n",
        "# Łączy dwie posortowane sekwencje danych w jedną większą posortowaną sekwencję\n",
        "\n",
        "# Używanie buforów do odczytu i zapisu minimalizuje liczbę operacji I/O, co jest istotne dla wydajności.\n",
        "\n",
        "# Zwracane metadane są przydatne do monitorowania i optymalizacji procesu scalania oraz do analizy wydajności algorytmu\n",
        "\n",
        "# Funkcja merge jest integralną częścią procesu sortowania zewnętrznego,\n",
        "# zapewniając efektywne scalanie posortowanych segmentów danych w jedną całość.\n",
        "\n",
        "def merge(first_source_path, second_source_path, dest_tape_path):\n",
        "\n",
        "    # inicjalizacja buforów\n",
        "\n",
        "    # t1_buffer to bufor do zapisu, który będzie zapisywać scalone dane do pliku określonego przez dest_tape_path\n",
        "    t1_buffer = WriteBuffer(dest_tape_path)\n",
        "\n",
        "    # t2_buffer i t3_buffer to bufory do odczytu, które będą odczytywać dane z plików określonych przez first_source_path i second_source_path\n",
        "    t2_buffer = ReadBuffer(first_source_path)\n",
        "    t3_buffer = ReadBuffer(second_source_path)\n",
        "\n",
        "    while t2_buffer.has_more() and t3_buffer.has_more():\n",
        "\n",
        "        # W każdej iteracji pętli wywoływana jest funkcja merge_runs,\n",
        "        # która scala dwie posortowane sekwencje danych(reprezentowane przez RunIterator dla t2_buffer i t3_buffer)\n",
        "        # i zapisuje wynik do t1_buffer\n",
        "        merge_runs(RunIterator(t2_buffer), RunIterator(t3_buffer), t1_buffer)\n",
        "\n",
        "\n",
        "    # jeśli którykolwiek z buforów do odczytu ma jeszcze nieprzetworzone rekordy,\n",
        "    # są one zapisywane bezpośrednio do bufora do zapisu (t1_buffer)\n",
        "    for r in t2_buffer:\n",
        "        t1_buffer.write_next(r)\n",
        "\n",
        "    for r in t3_buffer:\n",
        "        t1_buffer.write_next(r)\n",
        "\n",
        "    # Po zapisaniu wszystkich rekordów do t1_buffer, bufor jest opróżniany (flush),\n",
        "    # aby upewnić się, że wszystkie dane zostały fizycznie zapisane do pliku\n",
        "    t1_buffer.flush()\n",
        "\n",
        "    # Funkcja zwraca obiekt MetaInfo, który zawiera liczbę operacji odczytu z dysku (disk_reads_count),\n",
        "    # liczbę operacji zapisu na dysk (disk_writes_count) oraz liczbę posortowanych sekwencji (runs)\n",
        "    # zapisanych do docelowego pliku taśmowego (runs_written)\n",
        "\n",
        "    return MetaInfo(t2_buffer.disk_reads_count + t3_buffer.disk_reads_count,\n",
        "                    t1_buffer.disk_writes_count,\n",
        "                    t1_buffer.runs_written)"
      ],
      "metadata": {
        "id": "1sA0Jejv_Flq"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SortInfo:\n",
        "    def __init__(self, reads_count, writes_count, phases_count):\n",
        "\n",
        "        # reads_count: Liczba operacji odczytu wykonanych podczas sortowania\n",
        "        self.reads_count = reads_count\n",
        "        # writes_count: Liczba operacji zapisu wykonanych podczas sortowania\n",
        "        self.writes_count = writes_count\n",
        "        # phases_count: Liczba faz (iteracji) sortowania\n",
        "        self.phases_count = phases_count"
      ],
      "metadata": {
        "id": "hu-YEwd9E9kZ"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Funkcja tape_sort jest odpowiedzialna za sortowanie zewnętrzne dużego pliku, który nie mieści się w pamięci operacyjnej.\n",
        "\n",
        "# Używa strategii sortowania przez scalanie (merge sort), realizując operacje rozdzielania i scalania na dwóch dodatkowych plikach taśmowych.\n",
        "\n",
        "# Monitoruje i raportuje liczbę operacji odczytu, zapisu oraz liczbę faz sortowania, co umożliwia analizę wydajności i poprawność działania algorytmu.\n",
        "\n",
        "\n",
        "# tape_path: Ścieżka do pliku, który ma być posortowany.\n",
        "\n",
        "# print_after_phase: Flaga, która decyduje, czy wydrukować stan taśmy\n",
        "# po każdej fazie sortowania (domyślnie False)\n",
        "\n",
        "\n",
        "def tape_sort(tape_path, print_after_phase=False):\n",
        "    #pdb.set_trace()\n",
        "    # runs_written: Liczba serii zapisanych w ostatniej fazie scalania\n",
        "    runs_written = 0\n",
        "\n",
        "    # phases_count: Licznik faz sortowania\n",
        "    phases_count = 0\n",
        "\n",
        "    # reads_count: Liczba operacji odczytu wykonanych podczas sortowania\n",
        "    reads_count = 0\n",
        "\n",
        "    # writes_count: Liczba operacji zapisu wykonanych podczas sortowania\n",
        "    writes_count = 0\n",
        "\n",
        "    # while runs_written != 1: Pętla wykonuje się, dopóki nie zostanie utworzona jedna seria.\n",
        "    # Każda iteracja pętli reprezentuje jedną fazę sortowania.\n",
        "\n",
        "    while runs_written != 1:\n",
        "\n",
        "        # Funkcja distribute rozdziela dane z pliku źródłowego na dwa\n",
        "        # pliki taśmowe (/content/t2 i /content/t3).\n",
        "        # Wynikiem tej operacji jest obiekt MetaInfo zawierający liczbę odczytów i zapisów.\n",
        "        dist_info = distribute(tape_path, \"/content/t2.txt\", \"/content/t3.txt\")\n",
        "\n",
        "\n",
        "        # Funkcja merge scala dane z dwóch plików taśmowych do pliku docelowego (tape_path).\n",
        "        # Wynikiem tej operacji jest obiekt MetaInfo zawierający liczbę odczytów, zapisów i liczba serii (runs_count)\n",
        "        merge_info = merge(\"/content/t2.txt\", \"/content/t3.txt\", tape_path)\n",
        "\n",
        "\n",
        "        # aktualizacja liczby serii na podstawie wyniku operacji scalania\n",
        "        runs_written = merge_info.runs_count\n",
        "\n",
        "        # dodawanie liczby odczytów z operacji rozdzielania i scalania do całkowitego licznika odczytów.\n",
        "        reads_count += dist_info.reads_count\n",
        "        reads_count += merge_info.reads_count\n",
        "\n",
        "        # dodawanie liczby zapisów z operacji rozdzielania i scalania do całkowitego licznika zapisów\n",
        "        writes_count += dist_info.writes_count\n",
        "        writes_count += merge_info.writes_count\n",
        "\n",
        "        # Jeśli print_after_phase jest ustawione na True, stan taśmy jest drukowany po każdej fazie.\n",
        "        if print_after_phase:\n",
        "\n",
        "            # Wydrukowanie numeru fazy\n",
        "            print(f\"[ -v ] Phase {phases_count + 1}\")\n",
        "\n",
        "            # Funkcja drukująca zawartość taśmy\n",
        "            print_tape(tape_path)\n",
        "        # informacja o liczbie pozostałych serii do posortowania\n",
        "        print(f\"[ .. ] {runs_written} series remaining\")\n",
        "        # Inkrementacja licznika faz\n",
        "        phases_count += 1\n",
        "\n",
        "    # zwracam obiekt SortInfo zawierający liczbę odczytów, zapisów i faz sortowania, co pozwala na analizę wydajności algorytmu.\n",
        "    return SortInfo(reads_count, writes_count, phases_count)"
      ],
      "metadata": {
        "id": "L_QiN1q3C6a8"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pdb\n",
        "import itertools\n",
        "import math\n",
        "from random import randint\n",
        "\n",
        "# Zmienna should_run jest ustawiona na True, co oznacza,\n",
        "# że pętla główna będzie się wykonywać, dopóki nie zostanie zmieniona na False\n",
        "# (czyli do momentu, gdy użytkownik wpisze polecenie exit)\n",
        "should_run = True\n",
        "\n",
        "\n",
        "while should_run:\n",
        "\n",
        "    cmd_line = input(\"> \")\n",
        "    # rozpoczyna dopasowanie wzorca do listy argumentów wprowadzonych przez użytkownika\n",
        "    match cmd_line.split():\n",
        "        case [\"clear\", tape_path]:\n",
        "            print(f\"[ .. ] Clearing a tape {tape_path}\")\n",
        "            if os.path.isfile(tape_path):\n",
        "                os.remove(tape_path)\n",
        "                print(f\"[ :) ] Cleared the tape\")\n",
        "            else:\n",
        "                print(f\"[ :( ] There does not exist a tape at provided path\")\n",
        "\n",
        "\n",
        "        case [\"genrandom\", tape_path, number_of_records, *options]:\n",
        "\n",
        "            # Ten fragment sprawdza, czy w opcjach (options) znajduje się flaga \"o\".\n",
        "\n",
        "            if \"o\" in options:\n",
        "\n",
        "                # Jeśli tak, tworzy się nowy obiekt WriteBuffer dla podanej ścieżki tape_path bez trybu dodawania\n",
        "                write_buffer = WriteBuffer(tape_path)\n",
        "\n",
        "            # Jeśli flaga \"o\" nie jest obecna, tworzony jest WriteBuffer w trybie dodawania (append_mode=True),\n",
        "            # co oznacza, że nowe rekordy będą dopisywane na końcu istniejącej taśmy.\n",
        "            else:\n",
        "                write_buffer = WriteBuffer(\n",
        "                    tape_path, append_mode=True)\n",
        "\n",
        "            # Następnie generowane jest określoną liczbę (number_of_records) losowych rekordów\n",
        "            for i in range(int(number_of_records)):\n",
        "                # Każdy rekord składa się z losowej liczby elementów (od 1 do 15) z przedziału od 0 do 255\n",
        "                set_length = randint(1, 15)\n",
        "                new_set = []\n",
        "                while len(new_set) != set_length:\n",
        "                    new_suggestion = randint(0, 255)\n",
        "                    if new_suggestion not in new_set:\n",
        "                        new_set.append(new_suggestion)\n",
        "                new_record = Record(new_set)\n",
        "                # Rekordy te są dodawane do WriteBuffer za pomocą metody write_next\n",
        "                write_buffer.write_next(new_record)\n",
        "            write_buffer.flush()\n",
        "            print(f\"[ :) ] Added {number_of_records} new records to \" +\n",
        "                  f\"tape {tape_path}\")\n",
        "\n",
        "        case [\"display\", tape_path]:\n",
        "            print(f\"[ :) ] Displaying tape {tape_path}\")\n",
        "            print_tape(tape_path)\n",
        "        case [\"add\", tape_path, *set_elements]:\n",
        "            if len(set_elements) == 0:\n",
        "                print(\"[ :( ] No number was given\")\n",
        "                continue\n",
        "            set_elements = [int(x) for x in set_elements]\n",
        "            new_record = Record(set_elements)\n",
        "            write_buffer = WriteBuffer(tape_path, append_mode=True)\n",
        "            write_buffer.write_next(new_record)\n",
        "            write_buffer.flush()\n",
        "            print(f\"[ :) ] Dopisano podany rekord na taśmę\")\n",
        "        case [\"sort\", tape_path, *options]:\n",
        "            #pdb.set_trace()\n",
        "            print(f\"[ .. ] Sorting tape {tape_path}\")\n",
        "            print(f\"[ -v ] Displaying tape before sorting:\")\n",
        "            print_tape(tape_path)\n",
        "            if \"v\" in options:\n",
        "                sort_info = tape_sort(tape_path, print_after_phase=True)\n",
        "            else:\n",
        "                sort_info = tape_sort(tape_path)\n",
        "            print(f\"[ -v ] Displaying tape after sorting:\")\n",
        "            print_tape(tape_path)\n",
        "            print(f\"[ :) ] Tape {tape_path} sorted!\")\n",
        "            print(f\"[ -v ] Sorting metadata:\")\n",
        "            print(f\"[ .. ] Phase count: {sort_info.phases_count}\")\n",
        "            print(f\"[ .. ] Reads count: {sort_info.reads_count}\")\n",
        "            print(f\"[ .. ] Writes count: {sort_info.writes_count}\")\n",
        "        case [\"load\", tape_path, test_file_path]:\n",
        "            wb = WriteBuffer(tape_path, append_mode=True)\n",
        "            count = 0\n",
        "            with open(test_file_path) as test_file:\n",
        "                for line in test_file:\n",
        "                    set_numbers = [int(s) for s in line.rstrip().split()]\n",
        "                    new_record = Record(set_numbers)\n",
        "                    wb.write_next(new_record)\n",
        "                    count += 1\n",
        "            wb.flush()\n",
        "            print(f\"[ :) ] Added {count} records to tape\")\n",
        "        case [\"exit\"]:\n",
        "            print(\"[ :) ] Goodbye!\")\n",
        "            should_run = False\n",
        "        case _:\n",
        "            print(\"[ :( ] I don't know such a command\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2M3WSMEJgH6",
        "outputId": "894d299f-5032-495f-8c4d-f50d51ca9f3f"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "> help\n",
            "[ :( ] I don't know such a command\n",
            "> add fs/t1 44\n",
            "[ :) ] Dopisano podany rekord na taśmę\n",
            "> add fs/t1 55\n",
            "[ :) ] Dopisano podany rekord na taśmę\n",
            "> add fs/t1 12\n",
            "[ :) ] Dopisano podany rekord na taśmę\n",
            "> add fs/t1 42\n",
            "[ :) ] Dopisano podany rekord na taśmę\n",
            "> add fs/t1 94\n",
            "[ :) ] Dopisano podany rekord na taśmę\n",
            "> add fs/t1 18\n",
            "[ :) ] Dopisano podany rekord na taśmę\n",
            "> add fs/t1 06\n",
            "[ :) ] Dopisano podany rekord na taśmę\n",
            "> add fs/t1 67\n",
            "[ :) ] Dopisano podany rekord na taśmę\n",
            "> sort fs/t1 v\n",
            "[ .. ] Sorting tape fs/t1\n",
            "[ -v ] Displaying tape before sorting:\n",
            "[ .. ] Tape fs/t1\n",
            "\n",
            "Set [44]\n",
            "Set [55]\n",
            "~ series end ~\n",
            "Set [12]\n",
            "Set [42]\n",
            "Set [94]\n",
            "~ series end ~\n",
            "Set [18]\n",
            "~ series end ~\n",
            "Set [6]\n",
            "Set [67]\n",
            "~ series end ~\n",
            "\n",
            "[ ^- ] Series count: 4\n",
            "[ ^- ] Records count: 8\n",
            "[ -v ] Phase 1\n",
            "[ .. ] Tape fs/t1\n",
            "\n",
            "Set [12]\n",
            "Set [42]\n",
            "Set [44]\n",
            "Set [55]\n",
            "Set [94]\n",
            "~ series end ~\n",
            "Set [6]\n",
            "Set [18]\n",
            "Set [67]\n",
            "~ series end ~\n",
            "\n",
            "[ ^- ] Series count: 2\n",
            "[ ^- ] Records count: 8\n",
            "[ .. ] 2 series remaining\n",
            "[ -v ] Phase 2\n",
            "[ .. ] Tape fs/t1\n",
            "\n",
            "Set [6]\n",
            "Set [12]\n",
            "Set [18]\n",
            "Set [42]\n",
            "Set [44]\n",
            "Set [55]\n",
            "Set [67]\n",
            "Set [94]\n",
            "~ series end ~\n",
            "\n",
            "[ ^- ] Series count: 1\n",
            "[ ^- ] Records count: 8\n",
            "[ .. ] 1 series remaining\n",
            "[ -v ] Displaying tape after sorting:\n",
            "[ .. ] Tape fs/t1\n",
            "\n",
            "Set [6]\n",
            "Set [12]\n",
            "Set [18]\n",
            "Set [42]\n",
            "Set [44]\n",
            "Set [55]\n",
            "Set [67]\n",
            "Set [94]\n",
            "~ series end ~\n",
            "\n",
            "[ ^- ] Series count: 1\n",
            "[ ^- ] Records count: 8\n",
            "[ :) ] Tape fs/t1 sorted!\n",
            "[ -v ] Sorting metadata:\n",
            "[ .. ] Phase count: 2\n",
            "[ .. ] Reads count: 6\n",
            "[ .. ] Writes count: 6\n",
            "> exit\n",
            "[ :) ] Goodbye!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lhk4-kJ1P0ht"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}